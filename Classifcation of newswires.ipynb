{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "## In this example, we will verify the accuracy of classification of newswires with different numbers of epochs and at the end we will add L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982,)"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# Note that our indices were offset by 3\n",
    "# because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of ? co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and ? ? revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash ? per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "We can vectorize the data with the exact same code as in our previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "# Our vectorized training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# Our vectorized test data\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "# Our vectorized training labels\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "# Our vectorized test labels\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with epochs=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/6\n",
      "7982/7982 [==============================] - 2s 301us/step - loss: 2.8077 - acc: 0.5130 - val_loss: 1.8922 - val_acc: 0.6150\n",
      "Epoch 2/6\n",
      "7982/7982 [==============================] - 2s 247us/step - loss: 1.6439 - acc: 0.6561 - val_loss: 1.4405 - val_acc: 0.6830\n",
      "Epoch 3/6\n",
      "7982/7982 [==============================] - 2s 249us/step - loss: 1.3371 - acc: 0.7075 - val_loss: 1.2767 - val_acc: 0.7020\n",
      "Epoch 4/6\n",
      "7982/7982 [==============================] - 2s 247us/step - loss: 1.1721 - acc: 0.7412 - val_loss: 1.1785 - val_acc: 0.7320\n",
      "Epoch 5/6\n",
      "7982/7982 [==============================] - 2s 249us/step - loss: 1.0513 - acc: 0.7679 - val_loss: 1.0987 - val_acc: 0.7550\n",
      "Epoch 6/6\n",
      "7982/7982 [==============================] - 2s 251us/step - loss: 0.9622 - acc: 0.7870 - val_loss: 1.0515 - val_acc: 0.7670\n",
      "2246/2246 [==============================] - 1s 230us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=6,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.121917981073884, 0.7493321460639379]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see an accuracy of 74%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with epochs=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/8\n",
      "7982/7982 [==============================] - 3s 328us/step - loss: 2.8042 - acc: 0.5163 - val_loss: 1.9094 - val_acc: 0.6200\n",
      "Epoch 2/8\n",
      "7982/7982 [==============================] - 2s 250us/step - loss: 1.6251 - acc: 0.6642 - val_loss: 1.4332 - val_acc: 0.6820\n",
      "Epoch 3/8\n",
      "7982/7982 [==============================] - 2s 245us/step - loss: 1.3168 - acc: 0.7144 - val_loss: 1.2582 - val_acc: 0.7190\n",
      "Epoch 4/8\n",
      "7982/7982 [==============================] - 2s 250us/step - loss: 1.1653 - acc: 0.7444 - val_loss: 1.1953 - val_acc: 0.7230\n",
      "Epoch 5/8\n",
      "7982/7982 [==============================] - 2s 247us/step - loss: 1.0560 - acc: 0.7645 - val_loss: 1.1173 - val_acc: 0.7490\n",
      "Epoch 6/8\n",
      "7982/7982 [==============================] - 2s 247us/step - loss: 0.9583 - acc: 0.7838 - val_loss: 1.0666 - val_acc: 0.7550\n",
      "Epoch 7/8\n",
      "7982/7982 [==============================] - ETA: 0s - loss: 0.8805 - acc: 0.796 - 2s 251us/step - loss: 0.8810 - acc: 0.7970 - val_loss: 1.0150 - val_acc: 0.7840\n",
      "Epoch 8/8\n",
      "7982/7982 [==============================] - 2s 246us/step - loss: 0.8137 - acc: 0.8127 - val_loss: 0.9985 - val_acc: 0.7770\n",
      "2246/2246 [==============================] - 1s 244us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=8,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0605277361237142, 0.7537845057880677]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see an accuracy of 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "7982/7982 [==============================] - 4s 535us/step - loss: 2.7227 - acc: 0.4669 - val_loss: 1.8889 - val_acc: 0.6210\n",
      "Epoch 2/10\n",
      "7982/7982 [==============================] - 2s 294us/step - loss: 1.6459 - acc: 0.6636 - val_loss: 1.4596 - val_acc: 0.6800\n",
      "Epoch 3/10\n",
      "7982/7982 [==============================] - 2s 294us/step - loss: 1.3536 - acc: 0.7058 - val_loss: 1.2967 - val_acc: 0.7170\n",
      "Epoch 4/10\n",
      "7982/7982 [==============================] - 2s 291us/step - loss: 1.1852 - acc: 0.7424 - val_loss: 1.1776 - val_acc: 0.7430\n",
      "Epoch 5/10\n",
      "7982/7982 [==============================] - 2s 295us/step - loss: 1.0642 - acc: 0.7657 - val_loss: 1.1338 - val_acc: 0.7530\n",
      "Epoch 6/10\n",
      "7982/7982 [==============================] - 2s 313us/step - loss: 0.9685 - acc: 0.7843 - val_loss: 1.0636 - val_acc: 0.7650\n",
      "Epoch 7/10\n",
      "7982/7982 [==============================] - 2s 296us/step - loss: 0.8840 - acc: 0.7979 - val_loss: 1.0171 - val_acc: 0.7690\n",
      "Epoch 8/10\n",
      "7982/7982 [==============================] - 3s 338us/step - loss: 0.8148 - acc: 0.8123 - val_loss: 0.9979 - val_acc: 0.7820\n",
      "Epoch 9/10\n",
      "7982/7982 [==============================] - 3s 372us/step - loss: 0.7498 - acc: 0.8251 - val_loss: 0.9716 - val_acc: 0.7790\n",
      "Epoch 10/10\n",
      "7982/7982 [==============================] - 2s 311us/step - loss: 0.6940 - acc: 0.8395 - val_loss: 0.9415 - val_acc: 0.7890\n",
      "2246/2246 [==============================] - 1s 319us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=10,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9808251796189101, 0.7680320569902048]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see an accuracy of 76%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with epochs=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/15\n",
      "7982/7982 [==============================] - 3s 361us/step - loss: 2.6354 - acc: 0.4432 - val_loss: 1.7986 - val_acc: 0.6210\n",
      "Epoch 2/15\n",
      "7982/7982 [==============================] - 2s 255us/step - loss: 1.5796 - acc: 0.6656 - val_loss: 1.4213 - val_acc: 0.6930\n",
      "Epoch 3/15\n",
      "7982/7982 [==============================] - 2s 252us/step - loss: 1.3090 - acc: 0.7147 - val_loss: 1.2752 - val_acc: 0.7200\n",
      "Epoch 4/15\n",
      "7982/7982 [==============================] - 2s 261us/step - loss: 1.1580 - acc: 0.7409 - val_loss: 1.1757 - val_acc: 0.7340\n",
      "Epoch 5/15\n",
      "7982/7982 [==============================] - 2s 252us/step - loss: 1.0399 - acc: 0.7617 - val_loss: 1.1430 - val_acc: 0.7460\n",
      "Epoch 6/15\n",
      "7982/7982 [==============================] - 2s 252us/step - loss: 0.9489 - acc: 0.7840 - val_loss: 1.0761 - val_acc: 0.7550\n",
      "Epoch 7/15\n",
      "7982/7982 [==============================] - 2s 251us/step - loss: 0.8655 - acc: 0.7995 - val_loss: 1.0276 - val_acc: 0.7710\n",
      "Epoch 8/15\n",
      "7982/7982 [==============================] - 2s 256us/step - loss: 0.7971 - acc: 0.8118 - val_loss: 1.0269 - val_acc: 0.7670\n",
      "Epoch 9/15\n",
      "7982/7982 [==============================] - 2s 252us/step - loss: 0.7292 - acc: 0.8275 - val_loss: 0.9750 - val_acc: 0.7830\n",
      "Epoch 10/15\n",
      "7982/7982 [==============================] - 2s 259us/step - loss: 0.6690 - acc: 0.8410 - val_loss: 0.9602 - val_acc: 0.7850\n",
      "Epoch 11/15\n",
      "7982/7982 [==============================] - 2s 271us/step - loss: 0.6216 - acc: 0.8514 - val_loss: 0.9612 - val_acc: 0.7940\n",
      "Epoch 12/15\n",
      "7982/7982 [==============================] - 2s 254us/step - loss: 0.5825 - acc: 0.8603 - val_loss: 0.9559 - val_acc: 0.7830\n",
      "Epoch 13/15\n",
      "7982/7982 [==============================] - 2s 257us/step - loss: 0.5288 - acc: 0.8736 - val_loss: 0.9245 - val_acc: 0.7940\n",
      "Epoch 14/15\n",
      "7982/7982 [==============================] - 2s 269us/step - loss: 0.4968 - acc: 0.8805 - val_loss: 0.9382 - val_acc: 0.8010\n",
      "Epoch 15/15\n",
      "7982/7982 [==============================] - 2s 256us/step - loss: 0.4636 - acc: 0.8940 - val_loss: 0.9498 - val_acc: 0.7950\n",
      "2246/2246 [==============================] - 1s 247us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=15,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9950239666847915, 0.7662511130899377]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see an accuracy of 76%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 6s 710us/step - loss: 2.9491 - acc: 0.5085 - val_loss: 2.0301 - val_acc: 0.6220\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 2s 285us/step - loss: 1.6883 - acc: 0.6641 - val_loss: 1.4710 - val_acc: 0.6780\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 2s 267us/step - loss: 1.3228 - acc: 0.7184 - val_loss: 1.2595 - val_acc: 0.7230\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 2s 270us/step - loss: 1.1424 - acc: 0.7498 - val_loss: 1.1707 - val_acc: 0.7410\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 2s 260us/step - loss: 1.0263 - acc: 0.7700 - val_loss: 1.0866 - val_acc: 0.7590\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 2s 265us/step - loss: 0.9283 - acc: 0.7908 - val_loss: 1.0533 - val_acc: 0.7630\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 2s 265us/step - loss: 0.8544 - acc: 0.8034 - val_loss: 1.0076 - val_acc: 0.7790\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 2s 258us/step - loss: 0.7853 - acc: 0.8175 - val_loss: 1.0140 - val_acc: 0.7640\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 2s 263us/step - loss: 0.7240 - acc: 0.8292 - val_loss: 0.9497 - val_acc: 0.7930\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 2s 260us/step - loss: 0.6750 - acc: 0.8428 - val_loss: 0.9660 - val_acc: 0.7860\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 2s 262us/step - loss: 0.6273 - acc: 0.8550 - val_loss: 0.9397 - val_acc: 0.7920\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 2s 267us/step - loss: 0.5833 - acc: 0.8662 - val_loss: 0.9486 - val_acc: 0.7900\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 2s 262us/step - loss: 0.5442 - acc: 0.8748 - val_loss: 0.9563 - val_acc: 0.7850\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 2s 271us/step - loss: 0.5106 - acc: 0.8812 - val_loss: 0.9039 - val_acc: 0.8010\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 2s 279us/step - loss: 0.4735 - acc: 0.8894 - val_loss: 0.9120 - val_acc: 0.8010\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 2s 259us/step - loss: 0.4520 - acc: 0.8948 - val_loss: 0.9001 - val_acc: 0.8080\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 2s 267us/step - loss: 0.4163 - acc: 0.9027 - val_loss: 0.9207 - val_acc: 0.7990\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 2s 258us/step - loss: 0.3967 - acc: 0.9068 - val_loss: 0.9175 - val_acc: 0.8070\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 2s 267us/step - loss: 0.3760 - acc: 0.9114 - val_loss: 0.9092 - val_acc: 0.8110\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 2s 277us/step - loss: 0.3511 - acc: 0.9178 - val_loss: 0.9370 - val_acc: 0.8030\n",
      "2246/2246 [==============================] - 1s 323us/step\n"
     ]
    }
   ],
   "source": [
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(partial_x_train,\n",
    "              partial_y_train,\n",
    "              epochs=20,\n",
    "              batch_size=512,\n",
    "              validation_data=(x_val, y_val))\n",
    "    results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9904016764803009, 0.7773820124666073]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see an accuracy of 77%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can consider that 10 epochs is an optimal number to produce the maximum accuracy, if we increase the number of epochs the result will be always around 76%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_scores = []\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(46, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of K-fold validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/10\n",
      "1135/1135 [==============================] - 6s 5ms/step - loss: 3.8020 - acc: 0.1278\n",
      "Epoch 2/10\n",
      "1135/1135 [==============================] - 0s 320us/step - loss: 3.4010 - acc: 0.5304\n",
      "Epoch 3/10\n",
      "1135/1135 [==============================] - 0s 328us/step - loss: 2.9204 - acc: 0.5524\n",
      "Epoch 4/10\n",
      "1135/1135 [==============================] - 0s 329us/step - loss: 2.5172 - acc: 0.5841\n",
      "Epoch 5/10\n",
      "1135/1135 [==============================] - 0s 369us/step - loss: 2.2045 - acc: 0.6053\n",
      "Epoch 6/10\n",
      "1135/1135 [==============================] - 0s 373us/step - loss: 1.9484 - acc: 0.6344\n",
      "Epoch 7/10\n",
      "1135/1135 [==============================] - 0s 333us/step - loss: 1.7507 - acc: 0.6590\n",
      "Epoch 8/10\n",
      "1135/1135 [==============================] - 0s 332us/step - loss: 1.5983 - acc: 0.6722\n",
      "Epoch 9/10\n",
      "1135/1135 [==============================] - 0s 329us/step - loss: 1.4839 - acc: 0.6881\n",
      "Epoch 10/10\n",
      "1135/1135 [==============================] - 0s 358us/step - loss: 1.3717 - acc: 0.7154\n",
      "2246/2246 [==============================] - 3s 1ms/step\n",
      "processing fold # 1\n",
      "Epoch 1/10\n",
      "1135/1135 [==============================] - 5s 5ms/step - loss: 3.6527 - acc: 0.2705\n",
      "Epoch 2/10\n",
      "1135/1135 [==============================] - 0s 303us/step - loss: 2.9883 - acc: 0.4837\n",
      "Epoch 3/10\n",
      "1135/1135 [==============================] - 0s 296us/step - loss: 2.4743 - acc: 0.5463\n",
      "Epoch 4/10\n",
      "1135/1135 [==============================] - 0s 292us/step - loss: 2.1061 - acc: 0.5700\n",
      "Epoch 5/10\n",
      "1135/1135 [==============================] - 0s 298us/step - loss: 1.8598 - acc: 0.6018\n",
      "Epoch 6/10\n",
      "1135/1135 [==============================] - 0s 316us/step - loss: 1.6934 - acc: 0.6256\n",
      "Epoch 7/10\n",
      "1135/1135 [==============================] - 0s 315us/step - loss: 1.5446 - acc: 0.6590\n",
      "Epoch 8/10\n",
      "1135/1135 [==============================] - 0s 359us/step - loss: 1.4369 - acc: 0.6775\n",
      "Epoch 9/10\n",
      "1135/1135 [==============================] - 0s 349us/step - loss: 1.3284 - acc: 0.7048\n",
      "Epoch 10/10\n",
      "1135/1135 [==============================] - 0s 354us/step - loss: 1.2432 - acc: 0.7198\n",
      "2246/2246 [==============================] - 3s 1ms/step\n",
      "processing fold # 2\n",
      "Epoch 1/10\n",
      "1135/1135 [==============================] - 5s 5ms/step - loss: 3.7531 - acc: 0.2018\n",
      "Epoch 2/10\n",
      "1135/1135 [==============================] - 0s 341us/step - loss: 3.2309 - acc: 0.3762\n",
      "Epoch 3/10\n",
      "1135/1135 [==============================] - 0s 291us/step - loss: 2.6706 - acc: 0.4053\n",
      "Epoch 4/10\n",
      "1135/1135 [==============================] - 0s 303us/step - loss: 2.2575 - acc: 0.5348\n",
      "Epoch 5/10\n",
      "1135/1135 [==============================] - 0s 314us/step - loss: 1.9961 - acc: 0.5912\n",
      "Epoch 6/10\n",
      "1135/1135 [==============================] - 0s 306us/step - loss: 1.7830 - acc: 0.6097\n",
      "Epoch 7/10\n",
      "1135/1135 [==============================] - 0s 306us/step - loss: 1.6329 - acc: 0.6476\n",
      "Epoch 8/10\n",
      "1135/1135 [==============================] - 0s 316us/step - loss: 1.4863 - acc: 0.6740\n",
      "Epoch 9/10\n",
      "1135/1135 [==============================] - 0s 317us/step - loss: 1.3771 - acc: 0.6996\n",
      "Epoch 10/10\n",
      "1135/1135 [==============================] - 0s 337us/step - loss: 1.2881 - acc: 0.7198\n",
      "2246/2246 [==============================] - 3s 1ms/step\n",
      "processing fold # 3\n",
      "Epoch 1/10\n",
      "1135/1135 [==============================] - 5s 5ms/step - loss: 3.7426 - acc: 0.2449\n",
      "Epoch 2/10\n",
      "1135/1135 [==============================] - 0s 295us/step - loss: 3.2028 - acc: 0.5322\n",
      "Epoch 3/10\n",
      "1135/1135 [==============================] - 0s 296us/step - loss: 2.6747 - acc: 0.5348\n",
      "Epoch 4/10\n",
      "1135/1135 [==============================] - 0s 321us/step - loss: 2.2692 - acc: 0.5780\n",
      "Epoch 5/10\n",
      "1135/1135 [==============================] - 0s 353us/step - loss: 1.9826 - acc: 0.6035\n",
      "Epoch 6/10\n",
      "1135/1135 [==============================] - 0s 342us/step - loss: 1.7617 - acc: 0.6449\n",
      "Epoch 7/10\n",
      "1135/1135 [==============================] - 0s 341us/step - loss: 1.6013 - acc: 0.6899\n",
      "Epoch 8/10\n",
      "1135/1135 [==============================] - 0s 312us/step - loss: 1.4664 - acc: 0.7084\n",
      "Epoch 9/10\n",
      "1135/1135 [==============================] - 0s 312us/step - loss: 1.3562 - acc: 0.7278\n",
      "Epoch 10/10\n",
      "1135/1135 [==============================] - 0s 339us/step - loss: 1.2499 - acc: 0.7533\n",
      "2246/2246 [==============================] - 3s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 10\n",
    "all_scores = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    model = build_model()\n",
    "    \n",
    "    model.fit(x_train[train_index], one_hot_train_labels[train_index], epochs=num_epochs, batch_size=512)    \n",
    "    results, results2 = model.evaluate(x_test, one_hot_test_labels)\n",
    "    all_scores.append(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.625111309046843, 0.6544968834012508, 0.6353517364733791, 0.6567230632765847]"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of average of the four trainings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6429207480495144"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in this case the average is 64% while the accuracy on the computation presented in problem 1 shows an accuracy of 76%. Thus, using the original calculation with 10 epochs offers the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the original network with epochs =10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the effect of L2 regularization of epochs =10, first I ran the original model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "original_model = models.Sequential()\n",
    "original_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "original_model.add(layers.Dense(16, activation='relu'))\n",
    "original_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "original_model.compile(optimizer='rmsprop',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/10\n",
      "8982/8982 [==============================] - 4s 472us/step - loss: -9.3334 - acc: 0.0466 - val_loss: -20.7368 - val_acc: 0.0467\n",
      "Epoch 2/10\n",
      "8982/8982 [==============================] - 2s 213us/step - loss: -31.1882 - acc: 0.0481 - val_loss: -47.6230 - val_acc: 0.0467\n",
      "Epoch 3/10\n",
      "8982/8982 [==============================] - 2s 243us/step - loss: -58.5858 - acc: 0.0481 - val_loss: -74.1285 - val_acc: 0.0467\n",
      "Epoch 4/10\n",
      "8982/8982 [==============================] - 2s 218us/step - loss: -83.0741 - acc: 0.0481 - val_loss: -94.6759 - val_acc: 0.0467\n",
      "Epoch 5/10\n",
      "8982/8982 [==============================] - 2s 223us/step - loss: -101.0788 - acc: 0.0481 - val_loss: -109.0708 - val_acc: 0.0467\n",
      "Epoch 6/10\n",
      "8982/8982 [==============================] - 2s 221us/step - loss: -113.2166 - acc: 0.0481 - val_loss: -117.5196 - val_acc: 0.0467\n",
      "Epoch 7/10\n",
      "8982/8982 [==============================] - 2s 217us/step - loss: -119.3594 - acc: 0.0481 - val_loss: -121.6199 - val_acc: 0.0467\n",
      "Epoch 8/10\n",
      "8982/8982 [==============================] - 2s 186us/step - loss: -122.1261 - acc: 0.0481 - val_loss: -123.6147 - val_acc: 0.0467\n",
      "Epoch 9/10\n",
      "8982/8982 [==============================] - 2s 200us/step - loss: -123.7406 - acc: 0.0481 - val_loss: -124.7505 - val_acc: 0.0467\n",
      "Epoch 10/10\n",
      "8982/8982 [==============================] - 2s 186us/step - loss: -124.6924 - acc: 0.0481 - val_loss: -125.4707 - val_acc: 0.0467\n"
     ]
    }
   ],
   "source": [
    "original_hist = original_model.fit(x_train, y_train,\n",
    "                                   epochs=10,\n",
    "                                   batch_size=512,\n",
    "                                   validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_model = models.Sequential()\n",
    "smaller_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "smaller_model.add(layers.Dense(16, activation='relu'))\n",
    "smaller_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "smaller_model.compile(optimizer='rmsprop',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/10\n",
      "8982/8982 [==============================] - 7s 753us/step - loss: -1.8999 - acc: 0.0434 - val_loss: -6.6940 - val_acc: 0.0467\n",
      "Epoch 2/10\n",
      "8982/8982 [==============================] - 2s 238us/step - loss: -11.5589 - acc: 0.0481 - val_loss: -19.7597 - val_acc: 0.0467\n",
      "Epoch 3/10\n",
      "8982/8982 [==============================] - 2s 254us/step - loss: -28.2315 - acc: 0.0481 - val_loss: -41.7669 - val_acc: 0.0467\n",
      "Epoch 4/10\n",
      "8982/8982 [==============================] - 2s 267us/step - loss: -51.8117 - acc: 0.0481 - val_loss: -66.6368 - val_acc: 0.0467\n",
      "Epoch 5/10\n",
      "8982/8982 [==============================] - 2s 226us/step - loss: -76.0311 - acc: 0.0481 - val_loss: -88.4701 - val_acc: 0.0467\n",
      "Epoch 6/10\n",
      "8982/8982 [==============================] - 2s 192us/step - loss: -95.5657 - acc: 0.0481 - val_loss: -104.5473 - val_acc: 0.0467\n",
      "Epoch 7/10\n",
      "8982/8982 [==============================] - 2s 220us/step - loss: -109.5821 - acc: 0.0481 - val_loss: -115.0321 - val_acc: 0.0467\n",
      "Epoch 8/10\n",
      "8982/8982 [==============================] - 2s 234us/step - loss: -117.4840 - acc: 0.0481 - val_loss: -120.2683 - val_acc: 0.0467\n",
      "Epoch 9/10\n",
      "8982/8982 [==============================] - 2s 205us/step - loss: -121.1167 - acc: 0.0481 - val_loss: -122.9124 - val_acc: 0.0467\n",
      "Epoch 10/10\n",
      "8982/8982 [==============================] - 2s 226us/step - loss: -123.2129 - acc: 0.0481 - val_loss: -124.4190 - val_acc: 0.0467\n"
     ]
    }
   ],
   "source": [
    "smaller_model_hist = smaller_model.fit(x_train, y_train,\n",
    "                                       epochs=10,\n",
    "                                       batch_size=512,\n",
    "                                       validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding weight regularization with Lambda = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model = models.Sequential()\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu', input_shape=(10000,)))\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu'))\n",
    "l2_model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/10\n",
      "8982/8982 [==============================] - 4s 462us/step - loss: -18.3935 - acc: 0.0480 - val_loss: -41.2893 - val_acc: 0.0467\n",
      "Epoch 2/10\n",
      "8982/8982 [==============================] - 2s 228us/step - loss: -57.1127 - acc: 0.0481 - val_loss: -77.0821 - val_acc: 0.0467\n",
      "Epoch 3/10\n",
      "8982/8982 [==============================] - 2s 211us/step - loss: -88.3659 - acc: 0.0481 - val_loss: -101.5469 - val_acc: 0.0467\n",
      "Epoch 4/10\n",
      "8982/8982 [==============================] - 2s 202us/step - loss: -108.5377 - acc: 0.0481 - val_loss: -115.7287 - val_acc: 0.0467\n",
      "Epoch 5/10\n",
      "8982/8982 [==============================] - 2s 195us/step - loss: -118.4782 - acc: 0.0481 - val_loss: -121.4143 - val_acc: 0.0467\n",
      "Epoch 6/10\n",
      "8982/8982 [==============================] - 2s 204us/step - loss: -122.2487 - acc: 0.0481 - val_loss: -123.9290 - val_acc: 0.0467\n",
      "Epoch 7/10\n",
      "8982/8982 [==============================] - 2s 230us/step - loss: -124.0985 - acc: 0.0481 - val_loss: -125.1074 - val_acc: 0.0467\n",
      "Epoch 8/10\n",
      "8982/8982 [==============================] - 2s 204us/step - loss: -125.0147 - acc: 0.0481 - val_loss: -125.7452 - val_acc: 0.0467\n",
      "Epoch 9/10\n",
      "8982/8982 [==============================] - 2s 217us/step - loss: -125.4503 - acc: 0.0481 - val_loss: -125.9936 - val_acc: 0.0467\n",
      "Epoch 10/10\n",
      "8982/8982 [==============================] - 2s 214us/step - loss: -125.5898 - acc: 0.0481 - val_loss: -126.0594 - val_acc: 0.0467\n"
     ]
    }
   ],
   "source": [
    "l2_model_hist = l2_model.fit(x_train, y_train,\n",
    "                             epochs=10,\n",
    "                             batch_size=512,\n",
    "                             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, 11)\n",
    "original_val_loss = original_hist.history['val_loss']\n",
    "smaller_model_val_loss = smaller_model_hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing loss between original model and L2 regularized model with Lambda = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a7c7f6a908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "l2_model_val_loss = l2_model_hist.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, l2_model_val_loss, 'bo', label='L2-regularized model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking weight regularization with Lambda = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model = models.Sequential()\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.005),\n",
    "                          activation='relu', input_shape=(10000,)))\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.005),\n",
    "                          activation='relu'))\n",
    "l2_model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/10\n",
      "8982/8982 [==============================] - 5s 542us/step - loss: -16.3553 - acc: 0.0479 - val_loss: -35.2050 - val_acc: 0.0467\n",
      "Epoch 2/10\n",
      "8982/8982 [==============================] - 2s 231us/step - loss: -49.0726 - acc: 0.0481 - val_loss: -67.1280 - val_acc: 0.0467\n",
      "Epoch 3/10\n",
      "8982/8982 [==============================] - 2s 255us/step - loss: -77.8660 - acc: 0.0481 - val_loss: -91.3162 - val_acc: 0.0467\n",
      "Epoch 4/10\n",
      "8982/8982 [==============================] - 2s 212us/step - loss: -98.7123 - acc: 0.0481 - val_loss: -107.8139 - val_acc: 0.0467\n",
      "Epoch 5/10\n",
      "8982/8982 [==============================] - 2s 211us/step - loss: -112.4357 - acc: 0.0481 - val_loss: -117.1609 - val_acc: 0.0467\n",
      "Epoch 6/10\n",
      "8982/8982 [==============================] - 2s 210us/step - loss: -119.0078 - acc: 0.0481 - val_loss: -121.3648 - val_acc: 0.0467\n",
      "Epoch 7/10\n",
      "8982/8982 [==============================] - 2s 204us/step - loss: -121.9872 - acc: 0.0481 - val_loss: -123.5611 - val_acc: 0.0467\n",
      "Epoch 8/10\n",
      "8982/8982 [==============================] - 2s 207us/step - loss: -123.6704 - acc: 0.0481 - val_loss: -124.6480 - val_acc: 0.0467\n",
      "Epoch 9/10\n",
      "8982/8982 [==============================] - 2s 203us/step - loss: -124.5711 - acc: 0.0481 - val_loss: -125.3447 - val_acc: 0.0467\n",
      "Epoch 10/10\n",
      "8982/8982 [==============================] - 2s 210us/step - loss: -125.0854 - acc: 0.0481 - val_loss: -125.6804 - val_acc: 0.0467\n"
     ]
    }
   ],
   "source": [
    "l2_model_hist = l2_model.fit(x_train, y_train,\n",
    "                             epochs=10,\n",
    "                             batch_size=512,\n",
    "                             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing loss between original model and L2 regularized model with Lambda = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEKCAYAAADTgGjXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xt8FfW57/HPA6IxFsR6BSEELVpuASSAdlsQRamtiOC1J20FW2kVFbXHWk3dxPbQqqen7qqtbVREj9leCl5otRcpCi/dtCUocpEjYEswG1oDLSJGNMBz/phJWIkryWLIyswi3/frtV5r5jezZp4sAg+/y/x+5u6IiIhE0SnuAEREJHcpiYiISGRKIiIiEpmSiIiIRKYkIiIikSmJiIhIZEoiIiISmZKIiIhEpiQiIiKRHRR3ANl21FFHeWFhYdxhiIjkjGXLlm1x96MzOfeATyKFhYVUVlbGHYaISM4ws6pMz1VzloiIRKYkIiIikSmJiIhIZInrEzGz/w1MAD4G3gamuvu28NgtwNeB3cB17v772AIVSZi6ujqqq6vZuXNn3KFIjsjLy6NXr1506dIl8jUSl0SAF4Fb3H2Xmd0J3ALcbGYDgMuAgUBPYIGZneTuu2OMVSQxqqur6dq1K4WFhZhZ3OFIwrk7W7dupbq6mr59+0a+TuKas9z9D+6+K9z9E9Ar3J4IPOHuH7n734D1wMhsxlJWls2ri7StnTt3cuSRRyqBSEbMjCOPPHK/a66JSyJNXAH8Ntw+Hngn5Vh1WJY1t9+ezauLtD0lENkXbfH7EktzlpktAI5Lc6jU3Z8LzykFdgEV9R9Lc37atX3NbBowDaCgoGC/4xURkfRiqYm4+zh3H5TmVZ9ALgfOA0p87yLw1UDvlMv0AjY1c/1ydy929+Kjj87oocsGZWVgFryCWIKXmrZEWlddXc3EiRPp168fJ554IjNmzODjjz9Oe+6mTZu46KKLWr3mF7/4RbZt2xYpnrKyMn784x9H+mym5syZwzXXXLPf5+SqxDVnmdkXgJuB8929NuXQfOAyMzvEzPoC/YC/tPX9y8rAPXjB3m0lETlQtdXvtrszefJkLrjgAtatW8fatWvZsWMHpaWlnzh3165d9OzZk7lz57Z63RdeeIHu3bu3TZDS5hKXRID7gK7Ai2a23Mx+AeDuq4GngDeB3wHTNTJLZP+1Vd/fwoULycvLY+rUqQB07tyZu+++m9mzZ1NbW8ucOXO4+OKLmTBhAueccw4bNmxg0KBBANTW1nLJJZdQVFTEpZdeyqhRoxqmKyosLGTLli1s2LCB/v37c+WVVzJw4EDOOeccPvzwQwAeeOABRowYwZAhQ7jwwgupra1NH2RoypQpXHXVVYwdO5YTTjiBRYsWccUVV9C/f3+mTJnScN7jjz/O4MGDGTRoEDfffHND+cMPP8xJJ53EmDFjePXVVxvKa2pquPDCCxkxYgQjRoxodOxAlbgk4u6fcffe7j40fH0r5dgsdz/R3U9299+2dJ22MHNmtu8gcuBYvXo1w4cPb1TWrVs3CgoKWL9+PQBLlizhkUceYeHChY3O+/nPf84RRxzBihUruO2221i2bFnae6xbt47p06ezevVqunfvzrx58wCYPHkyS5cu5Y033qB///489NBDrcb7r3/9i4ULF3L33XczYcIEbrjhBlavXs3KlStZvnw5mzZt4uabb2bhwoUsX76cpUuX8uyzz7J582ZmzpzJq6++yosvvsibb77ZcM0ZM2Zwww03sHTpUubNm8c3vvGNffoOc1ESnxNJDDVhyYGqrKxxDaS+D3DmzOi/9+6edrRPavnZZ5/Npz/96U+c88orrzBjxgwABg0aRFFRUdp79O3bl6FDhwIwfPhwNmzYAMCqVav43ve+x7Zt29ixYwfjx49vNd4JEyZgZgwePJhjjz2WwYMHAzBw4EA2bNhAVVUVZ5xxBvX9qiUlJSxevBigUfmll17K2rVrAViwYEGjpLJ9+3bef//9VmPJZUoiIh1QWdneZGG2tw9wfwwcOLChZlBv+/btvPPOO5x44oksW7aMww47LO1nPcMADjnkkIbtzp07NzRnTZkyhWeffZYhQ4YwZ84cXn755Yyv1alTp0bX7dSpE7t27eKgg5r/57G5obF79uxhyZIlHHrooZn8OAeExDVniUhuOuuss6itreXRRx8FYPfu3Xz7299mypQp5Ofnt/jZ008/naeeegqAN998k5UrV+7Tvd9//3169OhBXV0dFRUVrX8gA6NGjWLRokVs2bKF3bt38/jjjzNmzBhGjRrFyy+/zNatW6mrq+NXv/pVw2fOOecc7rvvvob95cuXt0ksSaYkItLBtVXfn5nxzDPP8Ktf/Yp+/fpx0kknkZeXxw9/+MNWP3v11VdTU1NDUVERd955J0VFRRx++OEZ3/sHP/gBo0aN4uyzz+azn/3s/vwYDXr06MGPfvQjxo4dy5AhQzjllFOYOHEiPXr0oKysjNNOO41x48ZxyimnNHzmnnvuobKykqKiIgYMGMAvfvGLNoklySzTamSuKi4udi1KJR3BmjVr6N+/f9xhRLJ7927q6urIy8vj7bff5qyzzmLt2rUcfPDBcYd2wEv3e2Nmy9y9OJPPq09ERGJXW1vL2LFjqaurw925//77lUByhJKIiMSua9euWsY6R6lPREREIlMSERGRyJREREQkMiURERGJTElERNrMpz71qU+U/eQnP2HAgAEUFRVx1llnUVVV1e5xRZkSfv78+dxxxx37fe8zzjgj64MGpkyZ0uqMyJmcE4WSiEgHVVEBhYXQqVPw3kYPen/CsGHDqKysZMWKFVx00UV85zvfafUzu3btavWcbNq1axfnn38+3/3ud2ONIxcoiYh0QBUVMG0aVFUF82ZVVQX72UgkY8eObZj25NRTT6W6ujrteVOmTOHGG29k7Nix3HzzzXzwwQdcccUVjBgxgmHDhvHcc88BLU8bn1oTmjt3bqNp3es1N2180/unLiQ1dOjQhtehhx7KokWLmo3vww8/5LLLLmuIr35+r6YKCwu59dZbOe200yguLua1115j/PjxnHjiiQ1Purs7N910E4MGDWLw4ME8+eSTDeXXXHMNAwYM4Etf+hLvvvtuw3WXLVvGmDFjGD58OOPHj2fz5s2Z/UFFpOdERDqg0lJouuRGbW1QXlKSvfs+9NBDnHvuuc0eX7t2LQsWLKBz587ceuutnHnmmcyePZtt27YxcuRIxo0bx/33398wbfyqVasaZvXN1OTJk7nyyisB+N73vsdDDz3Etdde+4n7z5kzp+Ez9XNg/frXv+auu+7ic5/7HDNnzkwb3y9/+Uvy8/NZsWIFK1asaDQtSlO9e/dmyZIl3HDDDUyZMoVXX32VnTt3MnDgQL71rW/x9NNPs3z5ct544w22bNnCiBEjGD16NEuWLOGtt95i5cqV/OMf/2DAgAFcccUV1NXVce211/Lcc89x9NFH8+STT1JaWsrs2bP36TvaF0oiIh3Qxo37Vt4WHnvsMSorK1m0aFGz51x88cV07twZgD/84Q/Mnz+/oS9j586dbNy4MeNp45vT0rTxqfdvat26ddx0000sXLiQLl26NBvf4sWLue666wAoKipqMb7zzz8fgMGDB7Njxw66du1K165dycvLY9u2bbzyyit8+ctfpnPnzhx77LGMGTOGpUuXsnjx4obynj17cuaZZwLw1ltvsWrVKs4++2wgmE6mR48e+/T97CslEZEOqKAgaMJKV54NCxYsYNasWSxatKhh2vXS0lKef/55YO//9FOnind35s2bx8knn9zoWi3N95c6RfvOnTvTntPStPHNTVX/wQcfcMkll/DAAw/Qs2fPFuNrGkdLWpuOPtOftZ67M3DgQJYsWZLR/duC+kREOqBZs6Dp7Oz5+UF5W3v99df55je/yfz58znmmGNSYpjF8uXLm50uffz48dx7770N/5C+/vrrQMvTxh977LGsWbOGPXv28Mwzz6S9bpRp46dOncrUqVP5/Oc/32p8o0ePbrjuqlWrWLFiRUb3SGf06NE8+eST7N69m5qaGhYvXszIkSMZPXo0TzzxBLt372bz5s289NJLAJx88snU1NQ0JJG6ujpWr14d+f6ZUE1EpAOq7/coLQ2asAoKggSyv/0htbW19OrVq2H/xhtv5IUXXmDHjh1cfPHFABQUFDB//vxWr3Xbbbdx/fXXU1RUhLtTWFjIb37zG66++mouv/xyioqKGDZsWKNp4++44w7OO+88evfuzaBBg9ixY8cnrls/bXyfPn0YPHhwqysPVlVVMXfuXNauXdvQt/Dggw82G99VV13F1KlTKSoqYujQoYwcOTLj76+pSZMmsWTJEoYMGYKZcdddd3HccccxadIkFi5cyODBgxvWegc4+OCDmTt3Ltdddx3vvfceu3bt4vrrr2fgwIGRY2iNpoIXOUDk8lTw+0LTxret/Z0KXs1ZabTX+HkR2Xe1tbWcfvrpDBkyhEmTJmna+JipOauJ+vHz9cMf68fPQ3aHPopIZjRtfLKoJtJES+PnRZLuQG+elrbVFr8vSiJNxDF+XqQt5OXlsXXrViUSyYi7s3XrVvLy8vbrOmrOaqK9x8+LtJVevXpRXV1NTU1N3KFIjsjLy2s0mi4KJZEmZs1q3CcC2Rs/L9KWunTpQt++feMOQzoYNWc1UVIC5eXQpw+YBe/l5epUFxFJRzWRNEpKlDRERDKhmoiIiESW2CRiZv/TzNzMjgr3zczuMbP1ZrbCzJqfX1lERNpFIpOImfUGzgZSB9aeC/QLX9OA+2MITUREUiQyiQB3A98BUge8TwQe9cCfgO5mlt2J8kVEpEWJSyJmdj7w3+7+RpNDxwPvpOxXh2UiIhKTWEZnmdkC4Lg0h0qBW4Fz0n0sTVnaR3PNbBpBkxcFekpQRCRrYkki7j4uXbmZDQb6Am+Eq3b1Al4zs5EENY/eKaf3AjY1c/1yoByCqeDbLnIREUmVqOYsd1/p7se4e6G7FxIkjlPc/e/AfOBr4SitU4H33H1znPGKiHR0ufSw4QvAF4H1QC0wNd5wREQk0UkkrI3UbzswPb5oRESkqUQ1Z4mISG5REhERkciUREREJDIlERERiUxJREREIlMSERGRyJREckBZWdwRiIikpySSA26/Pe4IRETSUxIREZHIlEQSqqwMzIIX7N1W05aIJIkFs4kcuIqLi72ysjLuMPaLGRzgf0wikiBmtszdizM5VzURERGJTEkkB8ycGXcEIiLpKYnkAPWDiEhSKYmIiEhkSiIiIhKZkoiIiESmJCIiIpEpiYiISGRKIiIiEpmSiIiIRKYkIiIikbWaRMzsMDPrFG6fZGbnm1mX7IcmIiJJl0lNZDGQZ2bHA38EpgJzshmUiIjkhkySiLl7LTAZuNfdJwEDshuWiIjkgoySiJmdBpQAz4dlB2UvJBERyRWZJJHrgVuAZ9x9tZmdALyU3bBERCQXtFqjcPdFwCKAsIN9i7tfl+3AREQk+TIZnfWfZtbNzA4D3gTeMrObsh+aiIgkXSbNWQPcfTtwAfACUAB8NZtBmdm1ZvaWma02s7tSym8xs/XhsfHZjEFERFqXSQd5l/C5kAuA+9y9zsyytuK3mY0FJgJF7v6RmR0Tlg8ALgMGAj2BBWZ2krvvzlYsIiLSskxqIr8ENgCHAYvNrA+wPYsxXQXc4e4fAbj7u2H5ROAJd//I3f8GrAdGZjEOERFpRatJxN3vcffj3f2LHqgCxmYxppOAz5vZn81skZmNCMuPB95JOa86LPsEM5tmZpVmVllTU5PFUEVEOrZWm7PM7HBgJjA6LFoEfB94L+pNzWwBcFyaQ6VhTEcApwIjgKfCYcWW5vy0zWruXg6UAxQXF2et6U1EpKPLpE9kNrAKuCTc/yrwMMET7JG4+7jmjpnZVcDT7u7AX8xsD3AUQc2jd8qpvYBNUWMQEZH9l0mfyInuPtPd/xq+bgdOyGJMzwJnQjDhI3AwsAWYD1xmZoeYWV+gH/CXLMYhIiKtyKQm8qGZne7urwCY2b8BH2YxptnAbDNbBXwMXB7WSlab2VMEz6rsAqZrZJaISLwySSJXAY+EfSMG/BOYkq2A3P1j4CvNHJsFzMrWvUVEZN9kMu3JcmCImXUL97M5vFdERHJIs0nEzG5sphwAd/9JlmISEZEc0VJNpGu7RSEiIjmp2SQSjsISERFpViZDfEVERNJSEkmwigooLIROnYL3ioq4IxIRaUzL3CZURQVMmwa1tcF+VVWwD1BSEl9cIiKpLHiOr4UTzA4BLgQKSUk67v79rEbWRoqLi72ysjLuMPZZYWGQOJrq0wc2bGjvaESkIzGzZe5enMm5mdREniOYbHEZ8NH+BCaZ27hx38pFROKQSRLp5e5fyHok0khBQfqaSEFB+8ciItKcTDrW/8vMBmc9Emlk1izIz29clp8flIuIJEUmSeR0YFm4rvkKM1tpZiuyHVhHV1IC5eVBH4hZ8F5erk51EUmWTJqzzs16FJJWSYmShogkWybL41YB3YEJ4at7WCYiIh1cq0nEzGYAFcAx4esxM7s224GJiEjyZdKc9XVglLt/AGBmdwJLgHuzGZiIiCRfJh3rBqSuILg7LBMRkQ4uk5rIw8CfzeyZcP8C4KHshSQiIrkik471nwBTCZbF/Rcw1d3/I9uBSbKUlcUdgYgkUbNzZ5lZN3ffbmafTnfc3f+Z1cjaSK7OnZU0ZtDKNGsicoBoq7mz/hM4j2DOrNR/PizcPyFyhCIickBotjnL3c8L3/u6+wkpr77urgTSAZSVBTUQC4dR1G+raUtE6mXynMgfMymTA09ZWdCEVd+MVb+tJCIi9ZptzjKzPCAfOMrMjmDvsN5uQM92iE1ERBKupT6RbwLXEySMZexNItuBn2U5LkmYmTPjjkBEkiiTlQ2vdfecfTpdo7NERPZNm65s6O73mtkgYACQl1L+aPQQRUTkQNBqEjGzmcAZBEnkBYKp4V8BlERERDq4TObOugg4C/i7u08FhgCHZCsgMxtqZn8ys+VmVmlmI8NyM7N7zGx9uDjWKdmKQUREMpNJEvnQ3fcAu8ysG/Au2X3Q8C7gdncfCvx7uA9BDahf+JoG3J/FGEREJAOZTMBYaWbdgQcIRmntAP6SxZicYBgxwOHApnB7IvCoByMB/mRm3c2sh7tvzmIsIiLSgkw61q8ON39hZr8Durl7NtdYvx74vZn9mKCm9Lmw/HjgnZTzqsMyJRERkZi09LBhs30OZnaKu78W9aZmtgA4Ls2hUoL+lxvcfZ6ZXUIw7fw40q9hknZ8splNI2jyoqCgIGqYIiLSipZm8X0p3MwDioE3CP4hLwL+7O6nZyUgs/cI1nF3MzPgPXfvZma/BF5298fD894CzmitOUvPiYiI7Jt9eU6kpQkYx7r7WKAKOMXdi919ODAMWN82oaa1CRgTbp8JrAu35wNfC0dpnUqQXNSUJSISo0w61j/r7ivrd9x9lZkNzWJMVwI/NbODgJ2EzVIEz6h8kSCB1RIslCUiIjHKJImsMbMHgccI+iC+AqzJVkDu/gowPE25A9OzdV8REdl3mSSRqcBVwIxwfzF6RkNERMhsiO9O4O7wJSIi0qClIb5PufslZraSNENp3b0oq5GJiEjitVQTqW++Oq89AhERkdzTbBKpHz7r7lXtF46IiOSSlpqz3if9E+FGMFiqW5pjIiLSgbRUE+nanoGIiEjuyWSILwBmdgyNVzbcmJWIREQkZ7S6noiZnW9m64C/AYuADcBvsxyXiIjkgEwWpfoBcCqw1t37Esyy+2pWoxIRkZyQSRKpc/etQCcz6+TuLwHZnDtLRERyRCZ9ItvM7FME051UmNm7wK7shiUiIrkgk5rIROBD4Abgd8DbwIRsBiUiIrmh2SRiZveZ2efc/QN33+3uu9z9EXe/J2zekg6gogIKC6FTp+C9oiLuiEQkSVqqiawD/o+ZbTCzO7O8hogkUEUFTJsGVVXgHrxPm6ZEIiJ7tbSy4U/d/TSCVQb/CTxsZmvM7N/N7KR2i1BiU1oKtbWNy2prg3IREcigT8Tdq9z9TncfBvwPYBJZXJRKkmNjM4+TNlcuIh1PJg8bdjGzCWZWQfCQ4VrgwqxHJrErKNi3chHpeFrqWD/bzGYD1QTrnL8AnOjul7r7s+0VoMRn1izIz29clp8flIuIQMs1kVuBJUB/d5/g7hXu/kE7xSUJUFIC5eXQpw+YBe/l5UG5iAiAuaeb7f3AUVxc7JWVlXGHIW2krCx4iUj2mNkydy/O5NxMHjYUSYzbb487AhFJpSQiIiKRKYlI4pWVBX0yZsF+/baatUTipz4RySlmwdPzIpI96hMREZF2oSQiOWXmzLgjEJFUSiKSU9QPIpIsSiIiIhJZLEnEzC42s9VmtsfMipscu8XM1pvZW2Y2PqX8C2HZejP7bvtHLSIiTcVVE1kFTCZYcreBmQ0ALgMGAl8Afm5mnc2sM/Az4FxgAPDl8FwREYlRJmustzl3XwNg9QP/95oIPOHuHwF/M7P1wMjw2Hp3/2v4uSfCc99sn4hFRCSdpPWJHA+8k7JfHZY1Vy4iIjHKWk3EzBYAx6U5VOruzzX3sTRlTvpk1+wjZ2Y2jWD6egq0+IWISNZkLYm4+7gIH6sGeqfs9wI2hdvNlae7dzlQDsET6xHiEBGRDCStOWs+cJmZHWJmfYF+wF+ApUA/M+trZgcTdL7PjzFOEREhpo51M5sE3AscDTxvZsvdfby7rzazpwg6zHcB0919d/iZa4DfA52B2e6+Oo7YRURkL03AKCIijWgCRhERaRdKIiIiEpmSiIiIRKYkIiIikSmJiIhIZEoiIiISmZKI5ISKCigshE6dgveKirgjEhGI6WFDkX1RUQHTpkFtbbBfVRXsA5SUxBeXiKgmIjmgtHRvAqlXWxuUi0i8lEQk8TZu3Lfy9qC13kUCSiKSeM3N5h/nLP+33x7fvUWSRElEEm/WLMjPb1yWnx+Ui0i8lEQk8UpKoLwc+vQBs+C9vLz9O9XLyoL716/qXL+tpi3pyDSLr0gEZnCA/9WRDkyz+IqISLtQEhGJYObMuCMQSQYlEZEI1A8iElASERGRyJREREQkMiURERGJTElEREQiUxIREZHIlERERCQyJREREYlMSURkH2iFRZHGlEREMlS/wmJVVTBvVv0Ki3EmEj30KHHTBIwiGSosDBJHU336wIYN7R1NQBNBSjZoAkaRLEjiCosicVMSEclQUlZY1LomkiSxJBEzu9jMVpvZHjMrTik/28yWmdnK8P3MlGPDw/L1ZnaPWf1fIZH2kZQVFsvKgias+mas+m0lEYlDXDWRVcBkYHGT8i3ABHcfDFwO/N+UY/cD04B+4esL7RCnSIOkrLAokiQHxXFTd18D0LQy4e6vp+yuBvLM7BDg00A3d18Sfu5R4ALgt+0SsEiopCRZSUPrmkjcktwnciHwurt/BBwPVKccqw7L0jKzaWZWaWaVNTU1WQ5TpP3VP6/y/e8n43kVNaV1XFlLIma2wMxWpXlNzOCzA4E7gW/WF6U5rdmBje5e7u7F7l589NFHR/sBRBIqic+r3H57fPeWeGWtOcvdx0X5nJn1Ap4Bvubub4fF1UCvlNN6AZv2L0KR3FRaCrW1jctqa4PyJDW1SceQqOYsM+sOPA/c4u6v1pe7+2bgfTM7NRyV9TXguZjCFIlVUp5X0VBjgfiG+E4ys2rgNOB5M/t9eOga4DPAbWa2PHwdEx67CngQWA+8jTrVpYNK0vMqjz0WjFKD4P2xx+JNIkpg7U/TnojkmPo+kdQmrfz89h9unJQ4UmkamLahaU9EDmBJeV6lpb6Z9lY/Wg3iH63W0WpDqomISCSdOqX/X78Z7NnTfnFceCE8/fQnyydPhnnz2i+OiooggVZVBYl91qzcHeigmoiIZF1S+maWLdu38mxIHXYN8Q67rq+VmbVPrUxJREQiScpcYkkYrTZ9evqmvenT2y8GiCeZKYmISCRJ6ZtJQo1o+/Z9K8+WOPqplEREJLKSkmBBrj17gvc4+gCSUCNKQiKD9IumtVTeFpRERCSnJaFGlIREBnuf2cm0vC0oiYhIzou7RpSERAbxJLNYpoIXETnQJGGZgPr7t+dQYyUREZEDSHsnMzVniYhIZEoiIiISmZKIiIhEpiQiIiKRKYmIiEhkB/wsvmZWA2Txec12cRSwJe4gEkLfRWP6PhrT97HX/nwXfdz96ExOPOCTyIHAzCoznZb5QKfvojF9H43p+9irvb4LNWeJiEhkSiIiIhKZkkhuKI87gATRd9GYvo/G9H3s1S7fhfpEREQkMtVEREQkMiWRhDKz3mb2kpmtMbPVZjYj7piSwMw6m9nrZvabuGOJk5l1N7O5Zvb/wt+R0+KOKU5mdkP492SVmT1uZnlxx9SezGy2mb1rZqtSyj5tZi+a2brw/Yhs3FtJJLl2Ad929/7AqcB0MxsQc0xJMANYE3cQCfBT4Hfu/llgCB34OzGz44HrgGJ3HwR0Bi6LN6p2Nwf4QpOy7wJ/dPd+wB/D/TanJJJQ7r7Z3V8Lt98n+Efi+HijipeZ9QK+BDwYdyxxMrNuwGjgIQB3/9jdt8UbVewOAg41s4OAfGBTzPG0K3dfDPyzSfFE4JFw+xHggmzcW0kkB5hZITAM+HO8kcTuP4DvAHviDiRmJwA1wMNh096DZnZY3EHFxd3/G/gxsBHYDLzn7n+IN6pEONbdN0Pwn1LgmGzcREkk4czsU8A84Hp33x53PHExs/OAd919WdyxJMBBwCnA/e4+DPiALDVV5IKwrX8i0BfoCRxmZl+JN6qOQ0kkwcysC0ECqXD3p+OOJ2b/BpxvZhuAJ4AzzeyxeEOKTTVQ7e71NdO5BEmloxoH/M3da9y9Dnga+FzMMSXBP8ysB0D4/m42bqIkklBmZgRt3mvc/SdxxxM3d7/F3Xu5eyFBp+lCd++Q/9t0978D75jZyWHRWcCbMYYUt43AqWaWH/69OYsOPNAgxXzg8nD7cuC5bNxEa6wn178BXwVWmtnysOxWd38hxpgkOa4FKszsYOCvwNSY44mNu//ZzOYCrxGManyIrT9/AAACFElEQVSdDvbkupk9DpwBHGVm1cBM4A7gKTP7OkGivTgr99YT6yIiEpWas0REJDIlERERiUxJREREIlMSERGRyJREREQkMiURkQjMbLeZLU95tdkT42ZWmDobq0iS6TkRkWg+dPehcQchEjfVRETakJltMLM7zewv4eszYXkfM/ujma0I3wvC8mPN7BkzeyN81U/X0dnMHgjXyPiDmR0ann+dmb0ZXueJmH5MkQZKIiLRHNqkOevSlGPb3X0kcB/BzMOE24+6exFQAdwTlt8DLHL3IQTzX60Oy/sBP3P3gcA24MKw/LvAsPA638rWDyeSKT2xLhKBme1w90+lKd8AnOnufw0n0Py7ux9pZluAHu5eF5ZvdvejzKwG6OXuH6VcoxB4MVxMCDO7Geji7v/LzH4H7ACeBZ519x1Z/lFFWqSaiEjb82a2mzsnnY9Stnezt//yS8DPgOHAsnARJpHYKImItL1LU96XhNv/xd4lW0uAV8LtPwJXQcP68d2au6iZdQJ6u/tLBItzdQc+URsSaU/6X4xINIemzK4MwXrn9cN8DzGzPxP8J+3LYdl1wGwzu4lgVcL6WXdnAOXhTKu7CRLK5mbu2Rl4zMwOBwy4W8viStzUJyLShsI+kWJ33xJ3LCLtQc1ZIiISmWoiIiISmWoiIiISmZKIiIhEpiQiIiKRKYmIiEhkSiIiIhKZkoiIiET2/wH9rLYboebjHAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a7c83d5c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, 11)\n",
    "original_val_loss = original_hist.history['val_loss']\n",
    "smaller_model_val_loss = smaller_model_hist.history['val_loss']\n",
    "import matplotlib.pyplot as plt\n",
    "l2_model_val_loss = l2_model_hist.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, l2_model_val_loss, 'bo', label='L2-regularized model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking weight regularization with Lambda = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model = models.Sequential()\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.0005),\n",
    "                          activation='relu', input_shape=(10000,)))\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.0005),\n",
    "                          activation='relu'))\n",
    "l2_model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/10\n",
      "8982/8982 [==============================] - 4s 499us/step - loss: -18.2215 - acc: 0.0477 - val_loss: -41.7764 - val_acc: 0.0467\n",
      "Epoch 2/10\n",
      "8982/8982 [==============================] - 2s 201us/step - loss: -58.2041 - acc: 0.0481 - val_loss: -77.9773 - val_acc: 0.0467\n",
      "Epoch 3/10\n",
      "8982/8982 [==============================] - 2s 209us/step - loss: -88.5010 - acc: 0.0481 - val_loss: -100.9310 - val_acc: 0.0467\n",
      "Epoch 4/10\n",
      "8982/8982 [==============================] - 2s 203us/step - loss: -107.9690 - acc: 0.0481 - val_loss: -115.2836 - val_acc: 0.0467\n",
      "Epoch 5/10\n",
      "8982/8982 [==============================] - 2s 223us/step - loss: -118.1409 - acc: 0.0481 - val_loss: -121.1898 - val_acc: 0.0467\n",
      "Epoch 6/10\n",
      "8982/8982 [==============================] - 2s 222us/step - loss: -122.1001 - acc: 0.0481 - val_loss: -123.9194 - val_acc: 0.0467\n",
      "Epoch 7/10\n",
      "8982/8982 [==============================] - 2s 205us/step - loss: -124.0826 - acc: 0.0481 - val_loss: -125.1253 - val_acc: 0.0467\n",
      "Epoch 8/10\n",
      "8982/8982 [==============================] - 2s 187us/step - loss: -125.0229 - acc: 0.0481 - val_loss: -125.7351 - val_acc: 0.0467\n",
      "Epoch 9/10\n",
      "8982/8982 [==============================] - 2s 193us/step - loss: -125.4518 - acc: 0.0481 - val_loss: -126.0108 - val_acc: 0.0467\n",
      "Epoch 10/10\n",
      "8982/8982 [==============================] - 2s 191us/step - loss: -125.6113 - acc: 0.0481 - val_loss: -126.0848 - val_acc: 0.0467\n"
     ]
    }
   ],
   "source": [
    "l2_model_hist = l2_model.fit(x_train, y_train,\n",
    "                             epochs=10,\n",
    "                             batch_size=512,\n",
    "                             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing loss between original model and L2 regularized model with Lambda = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a7c8c771d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, 11)\n",
    "original_val_loss = original_hist.history['val_loss']\n",
    "smaller_model_val_loss = smaller_model_hist.history['val_loss']\n",
    "import matplotlib.pyplot as plt\n",
    "l2_model_val_loss = l2_model_hist.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, l2_model_val_loss, 'bo', label='L2-regularized model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
